{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png' alt=\"SUT logo\" width=300 height=300 align=center class=\"saturate\" >\n",
    "\n",
    "<br>\n",
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "    Artificial Intelligence <br>\n",
    "<font color=2565AE size=5>\n",
    "    Computer Engineering Department <br>\n",
    "    Fall 2024<br>\n",
    "<font color=3C99D size=5>\n",
    "    Practical Assignment 3 - Hidden Markov Model  <br>\n",
    "<font color=696880 size=4>\n",
    "Parsa Sharifi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set your student number and name\n",
    "student_number = None\n",
    "Name = None\n",
    "Last_Name = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8qksX5aqwnsS"
   },
   "source": [
    "!pip install hmmlearn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Th74QzY0zYrf"
   },
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PH0wMJE-wr5O"
   },
   "source": [
    "# Define a function to plot the hidden states\n",
    "def plot_hidden_states(model, X, lengths=None):\n",
    "    hidden_states = model.predict(X, lengths)\n",
    "\n",
    "    fig, axs = plt.subplots(model.n_components, sharex=True, sharey=True, figsize=(10, 8))\n",
    "    colors = plt.cm.get_cmap(\"viridis\", model.n_components)\n",
    "\n",
    "    for i, ax in enumerate(axs):\n",
    "        mask = hidden_states == i\n",
    "        ax.plot(X[mask], \".-\", color=colors(i), ms=6, label=f\"Hidden State {i}\")\n",
    "        ax.set_title(f\"Hidden State {i}\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HUwFHbnQyj0B"
   },
   "source": [
    "# Define the parameters of a more complex HMM with 4 hidden states and 4 possible observations\n",
    "\n",
    "# Transition probabilities (4x4 matrix for 4 hidden states)\n",
    "A = np.array([\n",
    "    [0.6, 0.1, 0.2, 0.1],\n",
    "    [0.2, 0.5, 0.2, 0.1],\n",
    "    [0.1, 0.3, 0.4, 0.2],\n",
    "    [0.3, 0.2, 0.2, 0.3]\n",
    "])\n",
    "\n",
    "# Emission probabilities (4x4 matrix for 4 states and 4 observations)\n",
    "B = np.array([\n",
    "    [0.5, 0.2, 0.2, 0.1],\n",
    "    [0.1, 0.3, 0.4, 0.2],\n",
    "    [0.2, 0.4, 0.1, 0.3],\n",
    "    [0.3, 0.1, 0.3, 0.3]\n",
    "])\n",
    "\n",
    "# Initial probabilities for 4 states\n",
    "pi = np.array([0.4, 0.3, 0.2, 0.1])\n",
    "\n",
    "# Generate a longer sequence of observations for more complexity\n",
    "observations = np.array([0, 1, 3, 2, 1, 0, 3, 3, 1, 2, 0, 1, 2, 3, 0, 1, 2, 2, 3, 1])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "402KFxnS1Xfg"
   },
   "source": [
    "# Viterbi Algorithm to determine the most probable state sequence\n",
    "\n",
    "def viterbi(obs, A, B, pi):\n",
    "    ''' your code '''\n",
    "    return Z, T1, T2\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi(obs, A, B, pi):\n",
    "    \"\"\"\n",
    "    Viterbi algorithm to find the most probable sequence of hidden states.\n",
    "\n",
    "    Parameters:\n",
    "    obs : list\n",
    "        Sequence of observed states.\n",
    "    A : 2D numpy array\n",
    "        State transition probability matrix.\n",
    "    B : 2D numpy array\n",
    "        Observation probability matrix.\n",
    "    pi : 1D numpy array\n",
    "        Initial state distribution.\n",
    "\n",
    "    Returns:\n",
    "    Z : list\n",
    "        The most probable sequence of hidden states.\n",
    "    T1 : 2D numpy array\n",
    "        Probability of the most likely path so far.\n",
    "    T2 : 2D numpy array\n",
    "        Backpointer to keep track of the states.\n",
    "    \"\"\"\n",
    "    # Number of states (N) and number of observations (T)\n",
    "    N = A.shape[0]\n",
    "    T = len(obs)\n",
    "\n",
    "    # Initialize T1 and T2 matrices\n",
    "    T1 = np.empty((T, N))\n",
    "    T2 = np.empty((T, N), dtype=int)\n",
    "\n",
    "    # Initialize T1 with the initial state distribution and observation likelihoods\n",
    "    for index in range(len(T1[0])):\n",
    "        T1[0][index] = pi[index] * B[index][obs[0]]\n",
    "    \n",
    "    # Dynamic programming to fill T1 and T2\n",
    "            # Calculate the probability for each state\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            max_p = 0\n",
    "            for i in range(N):\n",
    "                p = T1[t-1][i] * A[i][j] * B[j][obs[t]]\n",
    "                if p > max_p:\n",
    "                    max_p = p\n",
    "                    T2[t][j] = i\n",
    "            T1[t][j] = max_p\n",
    "    \n",
    "\n",
    "    # Start backtracking from the last state with the highest probability\n",
    "    p_star = 0\n",
    "    index_star = 0\n",
    "    for i in range(N):\n",
    "        if T1[T-1][i] > p_star:\n",
    "            p_star = T1[T-1][i]\n",
    "            index_star = i\n",
    "            \n",
    "    # Follow backpointers to reconstruct the path\n",
    "    Z = np.empty(T, dtype=int)\n",
    "    Z[T-1] = index_star\n",
    "    state = index_star\n",
    "    for i in range(T-2, -1, -1):\n",
    "        Z[i] = T2[i+1][state]\n",
    "        state = Z[i]\n",
    "        \n",
    "    return Z, T1, T2\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FVqbBSWX18jD"
   },
   "source": [
    "# Run the Viterbi algorithm\n",
    "optimal_path, T1, T2 = viterbi(observations, A, B, pi)\n",
    "print(\"Optimal state sequence (from scratch):\", optimal_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MbBv0vJ2ALz"
   },
   "source": [
    "Use hmmlearn and check the results:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KBdnxdXw1eJf"
   },
   "source": [
    "# Using hmmlearn CategoricalHMM to check the results\n",
    "try:\n",
    "\n",
    "    ''' your code '''\n",
    "\n",
    "    # Initialize a Hidden Markov Model with 4 hidden states\n",
    "    model = hmm.CategoricalHMM(n_components=4)\n",
    "\n",
    "    # Set the model's initial state probabilities\n",
    "    model.startprob_ = pi\n",
    "\n",
    "    # Set the transition probability matrix for the model\n",
    "    model.transmat_ = A\n",
    "\n",
    "    # Set the emission probability matrix, which defines probabilities of observations given each state\n",
    "    model.emissionprob_ = B\n",
    "\n",
    "    # Reshape the observations to match the expected input shape for hmmlearn (each observation as a separate row)\n",
    "    X = np.atleast_2d(observations).T\n",
    "\n",
    "    # Use the Viterbi algorithm to decode the sequence and find the most likely state sequence\n",
    "    state_sequence = model.predict(X)\n",
    "    \n",
    "    # Print the resulting optimal state sequence determined by the model\n",
    "    print(\"Optimal state sequence (using hmmlearn):\", state_sequence)\n",
    "\n",
    "\n",
    "    # Comparison of results\n",
    "    assert np.array_equal(optimal_path, state_sequence), \"Mismatch between custom implementation and hmmlearn!\"\n",
    "    print(\"Both implementations yield the same optimal state sequence.\")\n",
    "\n",
    "except AttributeError:\n",
    "    print(\"CategoricalHMM is not available in this hmmlearn version. Consider downgrading hmmlearn or using another library like pomegranate.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0vm7yen2Phi"
   },
   "source": [
    "Apply plot_hidden_states function and explain the results:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KuWzfIQwzpcz"
   },
   "source": "plot_hidden_states(model, X)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply forward-backward algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zayIz-Fy0Jcr"
   },
   "source": [
    "\n",
    "def forward_backward(obs, A, B, pi):\n",
    "    \"\"\"\n",
    "    Forward-Backward algorithm for HMMs.\n",
    "\n",
    "    Parameters:\n",
    "    obs : list\n",
    "        Sequence of observed states (encoded as integers).\n",
    "    A : 2D numpy array\n",
    "        State transition probability matrix.\n",
    "    B : 2D numpy array\n",
    "        Observation probability matrix.\n",
    "    pi : 1D numpy array\n",
    "        Initial state distribution.\n",
    "\n",
    "    Returns:\n",
    "    gamma : 2D numpy array\n",
    "        Posterior probabilities of states at each time step.\n",
    "    \"\"\"\n",
    "    N = A.shape[0]  # Number of states\n",
    "    T = len(obs)    # Number of observations\n",
    "\n",
    "    # Initialize alpha with the initial probabilities\n",
    "    alpha = np.zeros((T, N))\n",
    "    alpha[0, :] = pi * B[obs[0], :]  \n",
    "    \n",
    "    # Step 1: Forward procedure\n",
    "    for t in range(1, T):\n",
    "        observation = obs[t]\n",
    "        for j in range(N):\n",
    "            # p = 0\n",
    "            for i in range(N):\n",
    "                alpha[t][j] += alpha[t-1][i] * A[i][j] * B[j][obs[t]]\n",
    "            # alpha[t][j] = p\n",
    "      \n",
    "    # Termination  \n",
    "    p_forward = 0    \n",
    "    for i in range(N):\n",
    "        p_forward += alpha[T-1][i]\n",
    "        \n",
    "    # Step 2: Backward procedure\n",
    "    beta = np.empty((T, N))\n",
    "    beta[T-1, :] = 1  # Initialize beta with 1 at the last observation\n",
    "    \n",
    "    # Recursion\n",
    "    for t in range(T-2, -1, -1):\n",
    "        for i in range(N):\n",
    "            value = 0\n",
    "            for j in range(N):\n",
    "                value += beta[t+1][j] * A[i][j] * B[j][obs[t+1]]\n",
    "            beta[t][i] = value\n",
    "                \n",
    "    # Step 3: Calculate the posterior probabilities (gamma)\n",
    "    gamma = np.empty((T, N))\n",
    "    for t in range(T):\n",
    "        for i in range(N):\n",
    "            gamma[t][i] = alpha[t][i] * beta[t][i] / p_forward\n",
    "\n",
    "    return gamma, alpha, beta\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "gamma, alpha, beta = forward_backward(observations, A, B, pi)\n",
    "print(\"Posterior probabilities (gamma): \\n\", gamma)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
